{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import pandas as pd\n", "import os\n", "import duckdb"]}, {"cell_type": "markdown", "metadata": {}, "source": ["\n# Formatted to trusted:<br>\n", "Homogeneization of different version of data from same source into a single table.<br>\n", ""]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def formatted2trusted(duckdb_file_path, trusted_dir):\n", "    \"\"\" Homogenize .duckdb files from the same source and add timestamps in order to keep track of the version.\n", "    \"\"\"\n", "    # Initialize empty lists to store all the dataframes for Spotify and TicketMaster found in the formatted zone\n", "    spotify_dfs = []\n", "    ticketmaster_dfs = []\n\n", "    # Connect to the DuckDB file\n", "    con = duckdb.connect(database=duckdb_file_path, read_only=True)\n", "    tables = con.execute(\"SHOW TABLES\").fetchall()\n", "    for table in tables:\n", "        table_name = table[0]  # Extract table name from the result\n\n", "        # Extract the source (either \"spotify\" or \"ticketmaster\") and date from the table name\n", "        source, date = table_name.split('_', 1)         \n", "        df = con.execute(f\"SELECT * FROM {table_name}\").df()\n\n", "        # Add a new column with 'source_date' to store the date from the table name \n", "        df['source_date'] = date\n\n", "        # Check if the table is a \"spotify\" or \"ticketmaster\" table and append to the respective list\n", "        if 'spotify' in source:\n", "            spotify_dfs.append(df)\n", "        elif 'ticketmaster' in source:\n", "            ticketmaster_dfs.append(df)\n\n", "    # Close the connection after reading\n", "    con.close()\n\n", "    # Create the trusted directory if it doesn't exist\n", "    if not os.path.exists(trusted_dir):\n", "        os.makedirs(trusted_dir)\n\n", "    # Create the trusted DuckDB database\n", "    combined_duckdb_path = os.path.join(trusted_dir, 'trusted.duckdb')\n", "    con = duckdb.connect(database=combined_duckdb_path)\n\n", "    # Concatenate and save the resulting Spotify table into the DuckDB database\n", "    if spotify_dfs:\n", "        spotify_data = pd.concat(spotify_dfs, ignore_index=True)\n", "        con.execute(f\"DROP TABLE IF EXISTS {'spotify'}\") # drop the table if it already existed\n", "        con.execute(\"CREATE TABLE spotify AS SELECT * FROM spotify_data\")\n", "        print(f\"Spotify dataset dimensions: {spotify_data.shape}\")\n", "        print(\"Spotify datasets homogenized and saved into the DuckDB file.\")\n\n", "    # Concatenate and save the resulting TicketMaster table into the DuckDB database\n", "    if ticketmaster_dfs:\n", "        ticketmaster_data = pd.concat(ticketmaster_dfs, ignore_index=True)\n", "        con.execute(f\"DROP TABLE IF EXISTS {'ticketmaster'}\") # drop the table if it already existed\n", "        con.execute(\"CREATE TABLE ticketmaster AS SELECT * FROM ticketmaster_data\")\n", "        print(f\"TicketMaster dataset dimensions: {ticketmaster_data.shape}\")\n", "        print(\"TicketMaster datasets homogenized and saved into the DuckDB file.\")\n\n", "    # Close the DuckDB connection\n", "    con.close()"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["if __name__ == \"__main__\":\n", "    duckdb_file_path = input(\"Path to DuckDB file (input): \")\n", "    trustdir_out = input(\"Trusted directory path (output): \")\n", "    formatted2trusted(duckdb_file_path, trustdir_out)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}